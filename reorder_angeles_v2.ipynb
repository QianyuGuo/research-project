{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"reorder_angeles_v2.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"colab_type":"code","id":"Hb2bFkxYHGVm","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"2f0dd610-b080-45bf-a76a-57eaccd9581e","executionInfo":{"status":"ok","timestamp":1554297961604,"user_tz":-660,"elapsed":1497,"user":{"displayName":"Qianyu Guo","photoUrl":"","userId":"03435097776792169966"}}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"H16j1FfJpnjM","colab_type":"text"},"cell_type":"markdown","source":["**uitl类，data 的拆分操作， data_aprtition，evaluate_valid 和 evaluate函数**"]},{"metadata":{"id":"wmzUapFIkO7C","colab_type":"code","colab":{}},"cell_type":"code","source":["import sys\n","import copy\n","import random\n","import numpy as np\n","from collections import defaultdict\n","\n","\n","#拆分user和item\n","def data_partition():\n","    usernum = 0\n","    itemnum = 0\n","    User = defaultdict(list)\n","    user_train = {}\n","    user_valid = {}\n","    user_test = {}\n","    # assume user/item index starting from 1\n","    \n","    f = open('/content/gdrive/My Drive/caser/reorder_angeles.txt', 'r')\n","    for line in f:\n","        u, i= line.rstrip().split(',')\n","        u = int(u)\n","        i = int(i)\n","        #计算user的数目和item的数目\n","        usernum = max(u, usernum)\n","        itemnum = max(i, itemnum)\n","        User[u].append(i)\n","        #每个user都是一个字典？顺序加入item\n","\n","    for user in User:\n","        #判断user对应item的长度\n","        nfeedback = len(User[user])\n","        #如果小于3，就没有验证和测试集，有道理\n","        if nfeedback < 3:\n","            user_train[user] = User[user]\n","            user_valid[user] = []\n","            user_test[user] = []\n","        else:\n","            #如果大于3，倒数三项扣下来，其他的都是训练集\n","            user_train[user] = User[user][:-2]\n","            user_valid[user] = []\n","            #倒数第二项作为验证集\n","            user_valid[user].append(User[user][-2])\n","            user_test[user] = []\n","            #倒数第一项作为测试集\n","            user_test[user].append(User[user][-1])\n","    return [user_train, user_valid, user_test, usernum, itemnum]\n","\n","\n","def evaluate(model, dataset, args, sess):\n","    #print(10)\n","    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n","   # print(11)\n","    NDCG = 0.0\n","    NDCG_5 = 0.0\n","    HT = 0.0\n","    valid_user = 0.0\n","    HT_5 = 0.0\n","    #print(12)\n","    #print(usernum)\n","    if usernum>10000:\n","        #print(11111)\n","        users = random.sample(range(1, usernum + 1), 10000)\n","    else:\n","        #print(22222)\n","        users = range(1, usernum + 1)\n","    \n","    for u in users:\n","\n","        if len(train[u]) < 1 or len(test[u]) < 1: continue\n","\n","       #生成全是0的矩阵，类型是32位整数\n","        seq = np.zeros([args.maxlen], dtype=np.int)\n","        #这个应该是index\n","        idx = args.maxlen - 1\n","        seq[idx] = valid[u][0]\n","        idx -= 1\n","        for i in reversed(train[u]):\n","            seq[idx] = i\n","            idx -= 1\n","            if idx == -1: break\n","        rated = set(train[u])\n","        rated.add(0)\n","        item_idx = [test[u][0]]\n","        for i in range(itemnum):\n","              item_idx.append(i)\n","#         for _ in range(100):\n","#             t = np.random.randint(1, itemnum + 1)\n","#             while t in rated: t = np.random.randint(1, itemnum + 1)\n","#             item_idx.append(t)\n","        predictions = -model.predict(sess, [u], [seq], item_idx)\n","        predictions = predictions[0]\n","        rank = predictions.argsort().argsort()[0]\n","\n","        valid_user += 1\n","\n","        if rank < 5:\n","            NDCG_5 += 1 / np.log2(rank + 2)\n","            HT_5 += 1\n","        if rank < 20:\n","            NDCG += 1 / np.log2(rank + 2)\n","            HT += 1\n","        if valid_user % 100 == 0:\n","            #print ('.'),\n","            sys.stdout.flush()\n","\n","    return NDCG_5 /valid_user, NDCG / valid_user, HT_5 / valid_user, HT/valid_user\n","\n","\n","def evaluate_valid(model, dataset, args, sess):\n","    [train, valid, test, usernum, itemnum] = copy.deepcopy(dataset)\n","\n","    NDCG = 0.0\n","    NDCG_5 = 0.0\n","    valid_user = 0.0\n","    HT = 0.0\n","    HT_5 = 0.0\n","    if usernum>10000:\n","        users = random.sample(range(1, usernum + 1), 10000)\n","    else:\n","        users = range(1, usernum + 1)\n","    for u in users:\n","        if len(train[u]) < 1 or len(valid[u]) < 1: continue\n","\n","        seq = np.zeros([args.maxlen], dtype=np.int32)\n","        idx = args.maxlen - 1\n","        for i in reversed(train[u]):\n","            seq[idx] = i\n","            idx -= 1\n","            if idx == -1: break\n","\n","        rated = set(train[u])\n","        rated.add(0)\n","        item_idx = [valid[u][0]]\n","#         for _ in range(100):\n","#             t = np.random.randint(1, itemnum + 1)\n","#             while t in rated: t = np.random.randint(1, itemnum + 1)\n","#             item_idx.append(t)\n","        for i in range(itemnum):\n","              item_idx.append(i)\n","\n","        predictions = -model.predict(sess, [u], [seq], item_idx)\n","        predictions = predictions[0]\n","#         print('predictions')\n","#         print(predictions)\n","\n","        rank = predictions.argsort().argsort()[0]\n","#         print('rank')\n","#         print(rank)\n","\n","        valid_user += 1\n","        \n","        if rank < 5:\n","            NDCG_5 += 1 / np.log2(rank + 2)\n","            HT_5 += 1\n","        if rank < 20:\n","            NDCG += 1 / np.log2(rank + 2)\n","            HT += 1\n","        if valid_user % 100 == 0:\n","            #print ('.'),\n","            sys.stdout.flush()\n","\n","    return NDCG_5/valid_user, NDCG / valid_user, HT_5 /valid_user, HT/valid_user#, HT / valid_user"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SeksT65Zp4SB","colab_type":"text"},"cell_type":"markdown","source":["**sampler 类**"]},{"metadata":{"id":"Df7jlr1As17X","colab_type":"code","colab":{}},"cell_type":"code","source":["#sampler\n","import numpy as np\n","from multiprocessing import Process, Queue\n","\n","#随机产生一个1到r之间的数\n","def random_neq(l, r, s):\n","    t = np.random.randint(l, r)\n","    while t in s:\n","        t = np.random.randint(l, r)\n","    return t\n","\n","\n","def sample_function(user_train, usernum, itemnum, batch_size, maxlen, result_queue, SEED):\n","    def sample():\n","        #随机选一个user\n","        user = np.random.randint(1, usernum + 1)\n","        while len(user_train[user]) <= 1: user = np.random.randint(1, usernum + 1)\n","        #产生都是0的矩阵\n","        seq = np.zeros([maxlen], dtype=np.int32)\n","        pos = np.zeros([maxlen], dtype=np.int32)\n","        neg = np.zeros([maxlen], dtype=np.int32)\n","        #-1是验证集还是测试集来着\n","        nxt = user_train[user][-1]\n","        idx = maxlen - 1\n","        ts = set(user_train[user])\n","        #pos是虾米QWQ\n","        for i in reversed(user_train[user][:-1]):\n","            seq[idx] = i\n","            pos[idx] = nxt\n","            if nxt != 0: neg[idx] = random_neq(1, itemnum + 1, ts)\n","            nxt = i\n","            idx -= 1\n","            if idx == -1: break\n","\n","        return (user, seq, pos, neg)\n","\n","    np.random.seed(SEED)\n","    while True:\n","        one_batch = []\n","        for i in range(batch_size):\n","            one_batch.append(sample())\n","\n","        result_queue.put(zip(*one_batch))\n","\n","\n","class WarpSampler(object):\n","    def __init__(self, User, usernum, itemnum, batch_size=64, maxlen=10, n_workers=1):\n","        self.result_queue = Queue(maxsize=n_workers * 10)\n","        self.processors = []\n","        for i in range(n_workers):\n","            self.processors.append(\n","                Process(target=sample_function, args=(User,\n","                                                      usernum,\n","                                                      itemnum,\n","                                                      batch_size,\n","                                                      maxlen,\n","                                                      self.result_queue,\n","                                                      np.random.randint(2e9)\n","                                                      )))\n","            self.processors[-1].daemon = True\n","            self.processors[-1].start()\n","\n","    def next_batch(self):\n","        return self.result_queue.get()\n","\n","    def close(self):\n","        for p in self.processors:\n","            p.terminate()\n","            p.join()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RwKl2NxkqBUo","colab_type":"text"},"cell_type":"markdown","source":["**modules类**"]},{"metadata":{"id":"EMpjEGiutGMJ","colab_type":"code","colab":{}},"cell_type":"code","source":["#modules\n","\n","# -*- coding: utf-8 -*-\n","#/usr/bin/python2\n","'''\n","June 2017 by kyubyong park. \n","kbpark.linguist@gmail.com.\n","https://www.github.com/kyubyong/transformer\n","'''\n","\n","from __future__ import print_function\n","import tensorflow as tf\n","import numpy as np\n","\n","\n","def positional_encoding(dim, sentence_length, dtype=tf.float32):\n","\n","    encoded_vec = np.array([pos/np.power(10000, 2*i/dim) for pos in range(sentence_length) for i in range(dim)])\n","    encoded_vec[::2] = np.sin(encoded_vec[::2])\n","    encoded_vec[1::2] = np.cos(encoded_vec[1::2])\n","\n","    return tf.convert_to_tensor(encoded_vec.reshape([sentence_length, dim]), dtype=dtype)\n","\n","def normalize(inputs, \n","              epsilon = 1e-8,\n","              scope=\"ln\",\n","              reuse=None):\n","    '''Applies layer normalization.\n","    \n","    Args:\n","      inputs: A tensor with 2 or more dimensions, where the first dimension has\n","        `batch_size`.\n","      epsilon: A floating number. A very small number for preventing ZeroDivision Error.\n","      scope: Optional scope for `variable_scope`.\n","      reuse: Boolean, whether to reuse the weights of a previous layer\n","        by the same name.\n","      \n","    Returns:\n","      A tensor with the same shape and data dtype as `inputs`.\n","    '''\n","    with tf.variable_scope(scope, reuse=reuse):\n","        inputs_shape = inputs.get_shape()\n","        params_shape = inputs_shape[-1:]\n","    \n","        mean, variance = tf.nn.moments(inputs, [-1], keep_dims=True)\n","        beta= tf.Variable(tf.zeros(params_shape))\n","        gamma = tf.Variable(tf.ones(params_shape))\n","        normalized = (inputs - mean) / ( (variance + epsilon) ** (.5) )\n","        outputs = gamma * normalized + beta\n","        \n","    return outputs\n","\n","def embedding(inputs, \n","              vocab_size, \n","              num_units, \n","              zero_pad=True, \n","              scale=True,\n","              l2_reg=0.0,\n","              scope=\"embedding\", \n","              with_t=False,\n","              reuse=None):\n","    '''Embeds a given tensor.\n","\n","    Args:\n","      inputs: A `Tensor` with type `int32` or `int64` containing the ids\n","         to be looked up in `lookup table`.\n","      vocab_size: An int. Vocabulary size.\n","      num_units: An int. Number of embedding hidden units.\n","      zero_pad: A boolean. If True, all the values of the fist row (id 0)\n","        should be constant zeros.\n","      scale: A boolean. If True. the outputs is multiplied by sqrt num_units.\n","      scope: Optional scope for `variable_scope`.\n","      reuse: Boolean, whether to reuse the weights of a previous layer\n","        by the same name.\n","\n","    Returns:\n","      A `Tensor` with one more rank than inputs's. The last dimensionality\n","        should be `num_units`.\n","        \n","    For example,\n","    \n","    ```\n","    import tensorflow as tf\n","    \n","    inputs = tf.to_int32(tf.reshape(tf.range(2*3), (2, 3)))\n","    outputs = embedding(inputs, 6, 2, zero_pad=True)\n","    with tf.Session() as sess:\n","        sess.run(tf.global_variables_initializer())\n","        print sess.run(outputs)\n","    >>\n","    [[[ 0.          0.        ]\n","      [ 0.09754146  0.67385566]\n","      [ 0.37864095 -0.35689294]]\n","\n","     [[-1.01329422 -1.09939694]\n","      [ 0.7521342   0.38203377]\n","      [-0.04973143 -0.06210355]]]\n","    ```\n","    \n","    ```\n","    import tensorflow as tf\n","    \n","    inputs = tf.to_int32(tf.reshape(tf.range(2*3), (2, 3)))\n","    outputs = embedding(inputs, 6, 2, zero_pad=False)\n","    with tf.Session() as sess:\n","        sess.run(tf.global_variables_initializer())\n","        print sess.run(outputs)\n","    >>\n","    [[[-0.19172323 -0.39159766]\n","      [-0.43212751 -0.66207761]\n","      [ 1.03452027 -0.26704335]]\n","\n","     [[-0.11634696 -0.35983452]\n","      [ 0.50208133  0.53509563]\n","      [ 1.22204471 -0.96587461]]]    \n","    ```    \n","    '''\n","    with tf.variable_scope(scope, reuse=reuse):\n","        lookup_table = tf.get_variable('lookup_table',\n","                                       dtype=tf.float32,\n","                                       shape=[vocab_size, num_units],\n","                                       #initializer=tf.contrib.layers.xavier_initializer(),\n","                                       regularizer=tf.contrib.layers.l2_regularizer(l2_reg))\n","        if zero_pad:\n","            lookup_table = tf.concat((tf.zeros(shape=[1, num_units]),\n","                                      lookup_table[1:, :]), 0)\n","        outputs = tf.nn.embedding_lookup(lookup_table, inputs)\n","        \n","        if scale:\n","            outputs = outputs * (num_units ** 0.5) \n","    if with_t: return outputs,lookup_table\n","    else: return outputs\n","\n","\n","def multihead_attention(queries, \n","                        keys, \n","                        num_units=None, \n","                        num_heads=8, \n","                        dropout_rate=0,\n","                        is_training=True,\n","                        causality=False,\n","                        scope=\"multihead_attention\", \n","                        reuse=None,\n","                        with_qk=False):\n","    '''Applies multihead attention.\n","    \n","    Args:\n","      queries: A 3d tensor with shape of [N, T_q, C_q].\n","      keys: A 3d tensor with shape of [N, T_k, C_k].\n","      num_units: A scalar. Attention size.\n","      dropout_rate: A floating point number.\n","      is_training: Boolean. Controller of mechanism for dropout.\n","      causality: Boolean. If true, units that reference the future are masked. \n","      num_heads: An int. Number of heads.\n","      scope: Optional scope for `variable_scope`.\n","      reuse: Boolean, whether to reuse the weights of a previous layer\n","        by the same name.\n","        \n","    Returns\n","      A 3d tensor with shape of (N, T_q, C)  \n","    '''\n","    with tf.variable_scope(scope, reuse=reuse):\n","        # Set the fall back option for num_units\n","        if num_units is None:\n","            num_units = queries.get_shape().as_list[-1]\n","        \n","        # Linear projections\n","        # Q = tf.layers.dense(queries, num_units, activation=tf.nn.relu) # (N, T_q, C)\n","        # K = tf.layers.dense(keys, num_units, activation=tf.nn.relu) # (N, T_k, C)\n","        # V = tf.layers.dense(keys, num_units, activation=tf.nn.relu) # (N, T_k, C)\n","        Q = tf.layers.dense(queries, num_units, activation=None) # (N, T_q, C)\n","        K = tf.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n","        V = tf.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n","        \n","        # Split and concat\n","        Q_ = tf.concat(tf.split(Q, num_heads, axis=2), axis=0) # (h*N, T_q, C/h) \n","        K_ = tf.concat(tf.split(K, num_heads, axis=2), axis=0) # (h*N, T_k, C/h) \n","        V_ = tf.concat(tf.split(V, num_heads, axis=2), axis=0) # (h*N, T_k, C/h) \n","\n","        # Multiplication\n","        outputs = tf.matmul(Q_, tf.transpose(K_, [0, 2, 1])) # (h*N, T_q, T_k)\n","        \n","        # Scale\n","        outputs = outputs / (K_.get_shape().as_list()[-1] ** 0.5)\n","        \n","        # Key Masking\n","        key_masks = tf.sign(tf.abs(tf.reduce_sum(keys, axis=-1))) # (N, T_k)\n","        key_masks = tf.tile(key_masks, [num_heads, 1]) # (h*N, T_k)\n","        key_masks = tf.tile(tf.expand_dims(key_masks, 1), [1, tf.shape(queries)[1], 1]) # (h*N, T_q, T_k)\n","        \n","        paddings = tf.ones_like(outputs)*(-2**32+1)\n","        outputs = tf.where(tf.equal(key_masks, 0), paddings, outputs) # (h*N, T_q, T_k)\n","  \n","        # Causality = Future blinding\n","        if causality:\n","            diag_vals = tf.ones_like(outputs[0, :, :]) # (T_q, T_k)\n","            tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense() # (T_q, T_k)\n","            masks = tf.tile(tf.expand_dims(tril, 0), [tf.shape(outputs)[0], 1, 1]) # (h*N, T_q, T_k)\n","   \n","            paddings = tf.ones_like(masks)*(-2**32+1)\n","            outputs = tf.where(tf.equal(masks, 0), paddings, outputs) # (h*N, T_q, T_k)\n","  \n","        # Activation\n","        outputs = tf.nn.softmax(outputs) # (h*N, T_q, T_k)\n","         \n","        # Query Masking\n","        query_masks = tf.sign(tf.abs(tf.reduce_sum(queries, axis=-1))) # (N, T_q)\n","        query_masks = tf.tile(query_masks, [num_heads, 1]) # (h*N, T_q)\n","        query_masks = tf.tile(tf.expand_dims(query_masks, -1), [1, 1, tf.shape(keys)[1]]) # (h*N, T_q, T_k)\n","        outputs *= query_masks # broadcasting. (N, T_q, C)\n","          \n","        # Dropouts\n","        outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(is_training))\n","               \n","        # Weighted sum\n","        outputs = tf.matmul(outputs, V_) # ( h*N, T_q, C/h)\n","        \n","        # Restore shape\n","        outputs = tf.concat(tf.split(outputs, num_heads, axis=0), axis=2 ) # (N, T_q, C)\n","              \n","        # Residual connection\n","        outputs += queries\n","              \n","        # Normalize\n","        #outputs = normalize(outputs) # (N, T_q, C)\n"," \n","    if with_qk: return Q,K\n","    else: return outputs\n","\n","def feedforward(inputs, \n","                num_units=[2048, 512],\n","                scope=\"multihead_attention\", \n","                dropout_rate=0.2,\n","                is_training=True,\n","                reuse=None):\n","    '''Point-wise feed forward net.\n","    \n","    Args:\n","      inputs: A 3d tensor with shape of [N, T, C].\n","      num_units: A list of two integers.\n","      scope: Optional scope for `variable_scope`.\n","      reuse: Boolean, whether to reuse the weights of a previous layer\n","        by the same name.\n","        \n","    Returns:\n","      A 3d tensor with the same shape and dtype as inputs\n","    '''\n","    with tf.variable_scope(scope, reuse=reuse):\n","        # Inner layer\n","        params = {\"inputs\": inputs, \"filters\": num_units[0], \"kernel_size\": 1,\n","                  \"activation\": tf.nn.relu, \"use_bias\": True}\n","        outputs = tf.layers.conv1d(**params)\n","        outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(is_training))\n","        # Readout layer\n","        params = {\"inputs\": outputs, \"filters\": num_units[1], \"kernel_size\": 1,\n","                  \"activation\": None, \"use_bias\": True}\n","        outputs = tf.layers.conv1d(**params)\n","        outputs = tf.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(is_training))\n","        \n","        # Residual connection\n","        outputs += inputs\n","        \n","        # Normalize\n","        #outputs = normalize(outputs)\n","    \n","    return outputs"],"execution_count":0,"outputs":[]},{"metadata":{"id":"j9BXpLCdtVbL","colab_type":"code","colab":{}},"cell_type":"code","source":["\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bH4CMTlHqMQ_","colab_type":"text"},"cell_type":"markdown","source":["\n","**定义args类，替换原来的参数**"]},{"metadata":{"id":"_jm-4BCPl34O","colab_type":"code","colab":{}},"cell_type":"code","source":["class Args(object):\n","    \"\"\"docstring for Hotel\"\"\"\n","    def __init__(self,dataset = 'tokyo',train_dir='default', batch_size=128,lr=0.001,maxlen = 50,hidden_units=50,num_blocks = 2,num_epochs = 201,num_heads = 1,dropout_rate = 0.5,l2_emb =0.0 ):\n","        self.batch_size = batch_size\n","        self.lr = lr\n","        self.maxlen = maxlen\n","        self.hidden_units = hidden_units\n","        self.num_blocks = num_blocks\n","        self.num_epochs = num_epochs\n","        self.num_heads = num_heads\n","        self.dropout_rate = dropout_rate\n","        self.dataset =dataset\n","        self.train_dir = train_dir\n","        self.l2_emb=l2_emb\n","\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fIqIvbd3taOf","colab_type":"text"},"cell_type":"markdown","source":["**Model类**"]},{"metadata":{"id":"_PkHZMfDtjGU","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\n","class Model():\n","    def __init__(self, usernum, itemnum, args, reuse=None):\n","        self.is_training = tf.placeholder(tf.bool, shape=())\n","        self.u = tf.placeholder(tf.int32, shape=(None))\n","        self.input_seq = tf.placeholder(tf.int32, shape=(None, args.maxlen))\n","        self.pos = tf.placeholder(tf.int32, shape=(None, args.maxlen))\n","        self.neg = tf.placeholder(tf.int32, shape=(None, args.maxlen))\n","        pos = self.pos\n","        neg = self.neg\n","        mask = tf.expand_dims(tf.to_float(tf.not_equal(self.input_seq, 0)), -1)\n","\n","        with tf.variable_scope(\"SASRec\", reuse=reuse):\n","            # sequence embedding, item embedding table\n","            self.seq, item_emb_table = embedding(self.input_seq,\n","                                                 vocab_size=itemnum + 1,\n","                                                 num_units=args.hidden_units,\n","                                                 zero_pad=True,\n","                                                 scale=True,\n","                                                 l2_reg=args.l2_emb,\n","                                                 scope=\"input_embeddings\",\n","                                                 with_t=True,\n","                                                 reuse=reuse\n","                                                 )\n","\n","            # Positional Encoding\n","            t, pos_emb_table = embedding(\n","                tf.tile(tf.expand_dims(tf.range(tf.shape(self.input_seq)[1]), 0), [tf.shape(self.input_seq)[0], 1]),\n","                vocab_size=args.maxlen,\n","                num_units=args.hidden_units,\n","                zero_pad=False,\n","                scale=False,\n","                l2_reg=args.l2_emb,\n","                scope=\"dec_pos\",\n","                reuse=reuse,\n","                with_t=True\n","            )\n","            self.seq += t\n","\n","            # Dropout\n","            self.seq = tf.layers.dropout(self.seq,\n","                                         rate=args.dropout_rate,\n","                                         training=tf.convert_to_tensor(self.is_training))\n","            self.seq *= mask\n","\n","            # Build blocks\n","\n","            for i in range(args.num_blocks):\n","                with tf.variable_scope(\"num_blocks_%d\" % i):\n","\n","                    # Self-attention\n","                    self.seq = multihead_attention(queries=normalize(self.seq),\n","                                                   keys=self.seq,\n","                                                   num_units=args.hidden_units,\n","                                                   num_heads=args.num_heads,\n","                                                   dropout_rate=args.dropout_rate,\n","                                                   is_training=self.is_training,\n","                                                   causality=True,\n","                                                   scope=\"self_attention\")\n","\n","                    # Feed forward\n","                    self.seq = feedforward(normalize(self.seq), num_units=[args.hidden_units, args.hidden_units],\n","                                           dropout_rate=args.dropout_rate, is_training=self.is_training)\n","                    self.seq *= mask\n","\n","            self.seq = normalize(self.seq)\n","\n","        pos = tf.reshape(pos, [tf.shape(self.input_seq)[0] * args.maxlen])\n","        neg = tf.reshape(neg, [tf.shape(self.input_seq)[0] * args.maxlen])\n","        pos_emb = tf.nn.embedding_lookup(item_emb_table, pos)\n","        neg_emb = tf.nn.embedding_lookup(item_emb_table, neg)\n","        seq_emb = tf.reshape(self.seq, [tf.shape(self.input_seq)[0] * args.maxlen, args.hidden_units])\n","\n","        self.test_item = tf.placeholder(tf.int32, shape=(itemnum+1))\n","        test_item_emb = tf.nn.embedding_lookup(item_emb_table, self.test_item)\n","        self.test_logits = tf.matmul(seq_emb, tf.transpose(test_item_emb))\n","        self.test_logits = tf.reshape(self.test_logits, [tf.shape(self.input_seq)[0], args.maxlen, itemnum+1])\n","        self.test_logits = self.test_logits[:, -1, :]\n","\n","        # prediction layer\n","        self.pos_logits = tf.reduce_sum(pos_emb * seq_emb, -1)\n","        self.neg_logits = tf.reduce_sum(neg_emb * seq_emb, -1)\n","\n","        # ignore padding items (0)\n","        istarget = tf.reshape(tf.to_float(tf.not_equal(pos, 0)), [tf.shape(self.input_seq)[0] * args.maxlen])\n","        self.loss = tf.reduce_sum(\n","            - tf.log(tf.sigmoid(self.pos_logits) + 1e-24) * istarget -\n","            tf.log(1 - tf.sigmoid(self.neg_logits) + 1e-24) * istarget\n","        ) / tf.reduce_sum(istarget)\n","        reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n","        self.loss += sum(reg_losses)\n","\n","        tf.summary.scalar('loss', self.loss)\n","        self.auc = tf.reduce_sum(\n","            ((tf.sign(self.pos_logits - self.neg_logits) + 1) / 2) * istarget\n","        ) / tf.reduce_sum(istarget)\n","\n","        if reuse is None:\n","            tf.summary.scalar('auc', self.auc)\n","            self.global_step = tf.Variable(0, name='global_step', trainable=False)\n","            self.optimizer = tf.train.AdamOptimizer(learning_rate=args.lr, beta2=0.98)\n","            self.train_op = self.optimizer.minimize(self.loss, global_step=self.global_step)\n","        else:\n","            tf.summary.scalar('test_auc', self.auc)\n","\n","        self.merged = tf.summary.merge_all()\n","        #initialization the tensorboard\n","        train_writer = tf.summary.FileWriter( '/train', sess.graph)\n","        test_writer = tf.summary.FileWriter( '/test')\n","        with sess.as_default():\n","          tf.global_variables_initializer().run()\n","#         init = tf.global_variables_initializer()\n","#         sess = tf.Session()\n","#         sess.run(init)\n","#         merged = tf.summary.merge_all() #将图形、训练过程等数据合并在一起\n","#         writer = tf.summary.FileWriter('logs',sess.graph)\n","#         #将训练日志写入到logs文件夹下\n","\n","    def predict(self, sess, u, seq, item_idx):\n","        return sess.run(self.test_logits,\n","                        {self.u: u, self.input_seq: seq, self.test_item: item_idx, self.is_training: False})\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ebv0cdGLuWU0","colab_type":"text"},"cell_type":"markdown","source":["**main函数**"]},{"metadata":{"id":"wQxJL4HYtqer","colab_type":"code","outputId":"a35ee5e3-3140-4a64-edd1-acd21064b3ac","executionInfo":{"status":"ok","timestamp":1554298554007,"user_tz":-660,"elapsed":582431,"user":{"displayName":"Qianyu Guo","photoUrl":"","userId":"03435097776792169966"}},"colab":{"base_uri":"https://localhost:8080/","height":4588}},"cell_type":"code","source":["import os\n","import time\n","import argparse\n","import tensorflow as tf\n","from tqdm import tqdm\n","\n","\n","def str2bool(s):\n","    if s not in {'False', 'True'}:\n","        raise ValueError('Not a valid boolean string')\n","    return s == 'True'\n","\n","\n","\n","\n","args = Args()\n","\n","if not os.path.isdir(args.dataset + '_' + args.train_dir):\n","    os.makedirs(args.dataset + '_' + args.train_dir)\n","with open(os.path.join(args.dataset + '_' + args.train_dir, 'args.txt'), 'w') as f:\n","    f.write('\\n'.join([str(k) + ',' + str(v) for k, v in sorted(vars(args).items(), key=lambda x: x[0])]))\n","f.close()\n","\n","\n","dataset = data_partition()\n","[user_train, user_valid, user_test, usernum, itemnum] = dataset\n","num_batch = len(user_train) / args.batch_size\n","cc = 0.0\n","for u in user_train:\n","    cc += len(user_train[u])\n","print ('average sequence length: %.2f' % (cc / len(user_train)))\n","\n","f = open('/content/gdrive/My Drive/log.txt', 'w')\n","#f = open(os.path.join(args.dataset + '_' + args.train_dir, 'log.txt'), 'w')\n","config = tf.ConfigProto()\n","config.gpu_options.allow_growth = True\n","config.allow_soft_placement = True\n","sess = tf.Session(config=config)\n","\n","sampler = WarpSampler(user_train, usernum, itemnum, batch_size=args.batch_size, maxlen=args.maxlen, n_workers=3)\n","model = Model(usernum, itemnum, args)\n","sess.run(tf.initialize_all_variables())\n","\n","T = 0.0\n","t0 = time.time()\n","\n","try:\n","    for epoch in range(1, args.num_epochs + 1):\n","        print (num_batch)\n","        for step in tqdm(range(int(num_batch)), total=num_batch, ncols=70, leave=False, unit='b'):\n","            u, seq, pos, neg = sampler.next_batch()\n","            auc, loss, _ = sess.run([model.auc, model.loss, model.train_op],\n","                                    {model.u: u, model.input_seq: seq, model.pos: pos, model.neg: neg,\n","                                     model.is_training: True})\n","        if epoch % 20 == 0:\n","            t1 = time.time() - t0\n","            T += t1\n","            print ('Evaluating',)\n","\n","            t_valid = evaluate_valid(model, dataset, args, sess)\n","            t_test = evaluate(model, dataset, args, sess)\n","\n","            print ('epoch:%d, time: %f(s), valid (NDCG@5: %.4f, NDCG@20: %.4f,hit@5: %.4f, hit@20: %.4f), test (NDCG@5: %.4f, ndcg@20: %.4f,hit@5: %.4f, hit@20: %.4f)' % (\n","            epoch, T, t_valid[0], t_valid[1],t_valid[2], t_valid[3],t_test[0], t_test[1], t_test[2], t_test[3]))\n","\n","            f.write(str(t_valid) + ' ' + str(t_test) + '\\n')\n","            f.flush()\n","            t0 = time.time()\n","except:\n","    sampler.close()\n","    f.close()\n","    exit(1)\n","\n","f.close()\n","sampler.close()\n","print(\"Done\")\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["average sequence length: 29.64\n","WARNING:tensorflow:From <ipython-input-6-621e7721b1c1>:12: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","INFO:tensorflow:Scale of 0 disables regularizer.\n","WARNING:tensorflow:From <ipython-input-6-621e7721b1c1>:44: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dropout instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From <ipython-input-4-1838a9d62fe4>:167: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.dense instead.\n","WARNING:tensorflow:From <ipython-input-4-1838a9d62fe4>:248: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.conv1d instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n","Instructions for updating:\n","Use `tf.global_variables_initializer` instead.\n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|                                    | 0/25.015625 [00:00<?, ?b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.39b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.34b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.05b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 29.85b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.26b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.36b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.09b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 27.28b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.83b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.78b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.02b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.93b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.23b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.69b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.17b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.41b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 23.81b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 27.97b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.00b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[""],"name":"stderr"},{"output_type":"stream","text":["Evaluating\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 27.67b/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch:20, time: 19.009622(s), valid (NDCG@5: 0.0802, NDCG@20: 0.1152,hit@5: 0.1174, hit@20: 0.2402), test (NDCG@5: 0.1643, ndcg@20: 0.1998,hit@5: 0.2036, hit@20: 0.3279)\n","25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.62b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.41b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.99b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.58b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.99b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 33.07b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.06b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.09b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.98b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 27.40b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.41b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.88b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.14b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.86b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.66b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 27.42b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.78b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.64b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.33b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[""],"name":"stderr"},{"output_type":"stream","text":["Evaluating\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.33b/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch:40, time: 36.037514(s), valid (NDCG@5: 0.1305, NDCG@20: 0.1735,hit@5: 0.1893, hit@20: 0.3395), test (NDCG@5: 0.2125, ndcg@20: 0.2504,hit@5: 0.2764, hit@20: 0.4097)\n","25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.20b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.99b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.63b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.83b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.65b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.98b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.78b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.20b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.98b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.23b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.23b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.57b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 27.65b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.70b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.47b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.67b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.50b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.35b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.54b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[""],"name":"stderr"},{"output_type":"stream","text":["Evaluating\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.43b/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch:60, time: 52.942556(s), valid (NDCG@5: 0.1663, NDCG@20: 0.2036,hit@5: 0.2364, hit@20: 0.3663), test (NDCG@5: 0.2434, ndcg@20: 0.2811,hit@5: 0.3129, hit@20: 0.4438)\n","25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.08b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.63b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.19b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.75b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.17b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.83b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.79b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.74b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.71b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.04b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.52b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.59b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.61b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.02b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 27.84b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.51b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.90b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.88b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.67b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[""],"name":"stderr"},{"output_type":"stream","text":["Evaluating\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 27.29b/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch:80, time: 69.776150(s), valid (NDCG@5: 0.1759, NDCG@20: 0.2135,hit@5: 0.2458, hit@20: 0.3773), test (NDCG@5: 0.2539, ndcg@20: 0.2889,hit@5: 0.3276, hit@20: 0.4497)\n","25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.21b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.67b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.81b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.97b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.30b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.08b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.13b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.95b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.06b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.13b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.52b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.40b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.72b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.84b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.56b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.96b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.10b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.93b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.64b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[""],"name":"stderr"},{"output_type":"stream","text":["Evaluating\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.27b/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch:100, time: 86.621891(s), valid (NDCG@5: 0.1816, NDCG@20: 0.2206,hit@5: 0.2502, hit@20: 0.3866), test (NDCG@5: 0.2510, ndcg@20: 0.2908,hit@5: 0.3260, hit@20: 0.4641)\n","25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 27.87b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.59b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.81b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.71b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.40b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.11b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.36b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.95b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.17b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.47b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 33.11b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.41b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.21b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.92b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.75b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.89b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.82b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.69b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.93b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[""],"name":"stderr"},{"output_type":"stream","text":["Evaluating\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.60b/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch:120, time: 103.315697(s), valid (NDCG@5: 0.1827, NDCG@20: 0.2241,hit@5: 0.2448, hit@20: 0.3894), test (NDCG@5: 0.2465, ndcg@20: 0.2866,hit@5: 0.3251, hit@20: 0.4669)\n","25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.18b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.26b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.54b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.03b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.23b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.23b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.61b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.45b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.22b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.96b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.07b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.24b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.37b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.68b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.89b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.43b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.32b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.73b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.78b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[""],"name":"stderr"},{"output_type":"stream","text":["Evaluating\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.02b/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch:140, time: 119.976913(s), valid (NDCG@5: 0.1902, NDCG@20: 0.2300,hit@5: 0.2595, hit@20: 0.3991), test (NDCG@5: 0.2455, ndcg@20: 0.2858,hit@5: 0.3248, hit@20: 0.4647)\n","25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.12b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 27.59b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.88b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.01b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.69b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.58b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.21b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.46b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.69b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.05b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.51b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.43b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.73b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.31b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.25b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.32b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.39b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.44b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.29b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[""],"name":"stderr"},{"output_type":"stream","text":["Evaluating\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.79b/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch:160, time: 136.648286(s), valid (NDCG@5: 0.1884, NDCG@20: 0.2274,hit@5: 0.2589, hit@20: 0.3954), test (NDCG@5: 0.2464, ndcg@20: 0.2882,hit@5: 0.3245, hit@20: 0.4706)\n","25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.38b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.46b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.64b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.91b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.40b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 33.02b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.37b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.23b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.35b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.20b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.92b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.12b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.73b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.78b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.73b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.31b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.77b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.50b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.40b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[""],"name":"stderr"},{"output_type":"stream","text":["Evaluating\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.64b/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch:180, time: 153.788851(s), valid (NDCG@5: 0.1897, NDCG@20: 0.2302,hit@5: 0.2586, hit@20: 0.3998), test (NDCG@5: 0.2442, ndcg@20: 0.2851,hit@5: 0.3298, hit@20: 0.4725)\n","25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.07b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.59b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.55b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 28.01b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.30b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.39b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.07b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.54b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.89b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.41b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.48b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 30.85b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 32.00b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.38b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 26.65b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.61b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.57b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.89b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[" 16%|████▍                       | 4/25.015625 [00:00<00:00, 31.14b/s]"],"name":"stderr"},{"output_type":"stream","text":["25.015625\n"],"name":"stdout"},{"output_type":"stream","text":[""],"name":"stderr"},{"output_type":"stream","text":["Evaluating\n"],"name":"stdout"},{"output_type":"stream","text":[" 12%|███▎                        | 3/25.015625 [00:00<00:00, 29.08b/s]"],"name":"stderr"},{"output_type":"stream","text":["epoch:200, time: 170.736222(s), valid (NDCG@5: 0.1885, NDCG@20: 0.2306,hit@5: 0.2552, hit@20: 0.4001), test (NDCG@5: 0.2426, ndcg@20: 0.2864,hit@5: 0.3279, hit@20: 0.4791)\n","25.015625\n"],"name":"stdout"},{"output_type":"stream","text":["                                                                      "],"name":"stderr"},{"output_type":"stream","text":["Done\n"],"name":"stdout"},{"output_type":"stream","text":["\r"],"name":"stderr"}]}]}